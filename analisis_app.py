# --------------------------------------------------------------------------
# COMMENT ANALYSIS PLATFORM V13.0 - The Final Client-Ready Edition
# All inputs are processed; all errors are classified as Neutral.
# --------------------------------------------------------------------------
import streamlit as st
from PIL import Image
from sklearn.cluster import MiniBatchKMeans
import numpy as np
import pandas as pd
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import google.generativeai as genai
import time
import emoji
from collections import Counter
import concurrent.futures
import re
import json

# --- Page Configuration ---
st.set_page_config(page_title="Comment Analysis", layout="wide")

# --- STYLE INJECTION ---
st.markdown("""
<style>
    .stApp { background-color: #F0F2F6; }
    .stButton>button { background-color: #8A2BE2; color: #FFFFFF; border-radius: 8px; border: none; padding: 10px 20px; font-weight: bold; }
    .stButton>button:hover { background-color: #7B1FA2; }
    .st-emotion-cache-1r4qj8v, .st-emotion-cache-0 { background-color: #FFFFFF; border-radius: 10px; padding: 25px; box-shadow: 0 4px 6px rgba(0,0,0,0.05); }
</style>
""", unsafe_allow_html=True)


# --- CORE FUNCTIONS ---
def parse_ai_batch_response(response_text, original_batch):
    """Parses the structured JSON-like response from the AI for a batch."""
    try:
        if "```json" in response_text:
            json_str = response_text.split("```json")[1].split("```")[0]
        else:
            json_str = response_text
        analyses = json.loads(json_str)
        for i, analysis in enumerate(analyses):
            if i < len(original_batch):
                analysis['Original Comment'] = original_batch[i]
        return analyses
    except (json.JSONDecodeError, IndexError):
        # CHANGE: If parsing fails, classify the whole batch as Neutral.
        return [{'Original Comment': c, 'Sentiment': 'Neutral', 'Explanation': 'Unanalyzable content.'} for c in original_batch]

@st.cache_data(ttl="24h")
def analyze_comment_batch_cached(_api_key, comment_batch):
    """Worker function to analyze a BATCH of comments."""
    genai.configure(api_key=_api_key)
    model = genai.GenerativeModel('gemini-1.5-pro')
    
    comments_str = "\n".join([f'{i+1}. "{comment}"' for i, comment in enumerate(comment_batch)])
    prompt = f"""
    Act as a sentiment analysis API. Analyze EACH of the following customer comments.
    Your response MUST be a single, valid JSON array `[]` containing one JSON object `{{}}` for each comment.
    Maintain the original order.
    Each JSON object must have these exact keys: "Sentiment", "Explanation".
    - Sentiment: Must be one of "Positive", "Negative", or "Neutral".
    - Explanation: A concise justification for the sentiment.
    - If a comment is nonsensical (e.g., a single letter) or you cannot determine a sentiment, classify it as "Neutral".

    COMMENT LIST:
    {comments_str}
    """
    try:
        response = model.generate_content(prompt)
        return parse_ai_batch_response(response.text, comment_batch)
    except Exception:
        # CHANGE: If the API call itself fails, classify the whole batch as Neutral.
        return [{'Original Comment': c, 'Sentiment': 'Neutral', 'Explanation': 'Unanalyzable content (API error).'} for c in comment_batch]

def run_batch_analysis(api_key, comments):
    """Manages concurrent execution of BATCH comment analysis."""
    results = []
    batch_size = 50
    comment_batches = [comments[i:i + batch_size] for i in range(0, len(comments), batch_size)]
    with st.spinner(f"Analyzing {len(comments)} comments in {len(comment_batches)} batches..."):
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            future_to_batch = {executor.submit(analyze_comment_batch_cached, api_key, batch): batch for batch in comment_batches}
            for future in concurrent.futures.as_completed(future_to_batch):
                results.extend(future.result())
    return pd.DataFrame(results)

def load_comments_from_source(uploaded_file, gsheets_link, text_input):
    """Intelligently loads and validates comments from the provided source."""
    if uploaded_file:
        try:
            df = pd.read_excel(uploaded_file, header=None)
            return df.iloc[:, 0].dropna().astype(str).tolist()
        except Exception as e: st.error(f"Error reading Excel file: {e}"); return []
    if gsheets_link:
        pattern = re.compile(r'^https:\/\/docs\.google\.com\/spreadsheets\/d\/[a-zA-Z0-9_-]+(\/edit.*)?$')
        if not pattern.match(gsheets_link):
            st.error("Invalid URL. Please paste a valid Google Sheets sharing link."); return []
        try:
            url_csv = gsheets_link.replace('/edit?usp=sharing', '/export?format=csv').split('/edit')[0] + '/export?format=csv'
            df = pd.read_csv(url_csv, header=None, engine='python', on_bad_lines='skip')
            return df.iloc[:, 0].dropna().astype(str).tolist()
        except Exception as e:
            st.error(f"Error reading Google Sheets. Ensure the link is public ('Anyone with the link'). Error: {e}"); return []
    if text_input:
        return [line.strip() for line in text_input.split('\n') if line.strip()]
    return []
# Esta es una nueva "receta" para tu dibujante
# Le dice c√≥mo sacar los colores principales de una imagen
def extract_colors_from_image(image_file, num_colors=5):
    """
    Saca los colores principales de una foto.
    Devuelve una lista de los c√≥digos de esos colores.
    """
    img = Image.open(image_file).convert("RGB")
    img = img.resize((100, 100)) # Hacemos la imagen peque√±a para que sea m√°s r√°pido
    pixels = np.array(img).reshape(-1, 3) # Convertimos la imagen en una lista de puntos de color

    # Usamos una herramienta inteligente para agrupar colores parecidos
    kmeans = MiniBatchKMeans(n_clusters=num_colors, n_init=10, random_state=42)
    kmeans.fit(pixels)
    dominant_colors_rgb = kmeans.cluster_centers_.astype(int)

    # Convertimos los colores a un formato que tu dibujante entienda (c√≥digo hexadecimal)
    hex_colors = ['#%02x%02x%02x' % (r, g, b) for r, g, b in dominant_colors_rgb]
    return hex_colors

def generate_visuals(df, sentiment_colors, wordcloud_color_func=None):
    """Generates all visual elements for the dashboard."""
    visuals = {};
    if df.empty: return visuals
    
    # Clean up sentiment labels, just in case
    df['Sentiment'] = df['Sentiment'].str.strip().str.replace(r'[\[\]]', '', regex=True)
    
    # --- Sentiment Chart ---
    # CHANGE: Removed 'Error' from the map and order.
    sentiment_counts = df['Sentiment'].value_counts()
    # Usa los colores que t√∫ elijas para cada sentimiento
    color_map_sentiment = {
        'Positive': sentiment_colors.get('Positive', '#2ca02c'), # Si no hay color, usa el verde por defecto
        'Negative': sentiment_colors.get('Negative', '#d62728'), # Si no hay color, usa el rojo por defecto
        'Neutral': sentiment_colors.get('Neutral', '#ff7f0e')   # Si no hay color, usa el naranja por defecto
    }
    plot_order = [s for s in ['Positive', 'Negative', 'Neutral'] if s in sentiment_counts.index]
    
    fig_sent, ax_sent = plt.subplots(figsize=(8, 5)) # Un tama√±o mejor para el gr√°fico
    if not sentiment_counts.loc[plot_order].empty:
        # Aseg√∫rate de que solo se usen los colores de los sentimientos que existen
        colors_to_plot = [color_map_sentiment.get(s, '#cccccc') for s in plot_order]
        sentiment_counts.loc[plot_order].plot(kind='bar', ax=ax_sent, color=colors_to_plot)
        ax_sent.set_ylabel('Number of Comments')
        ax_sent.set_xticklabels(ax_sent.get_xticklabels(), rotation=0)
        ax_sent.set_title('Sentiment Distribution', fontsize=16) # Ponemos un t√≠tulo al gr√°fico
    plot_order = [s for s in ['Positive', 'Negative', 'Neutral'] if s in sentiment_counts.index]
    
    fig_sent, ax_sent = plt.subplots();
    if not sentiment_counts.loc[plot_order].empty:
        sentiment_counts.loc[plot_order].plot(kind='bar', ax=ax_sent, color=[color_map.get(s) for s in plot_order])
        ax_sent.set_ylabel('Number of Comments'); ax_sent.set_xticklabels(ax_sent.get_xticklabels(), rotation=0)
        total = len(df)
        for p in ax_sent.patches:
            percentage = f'{100 * p.get_height() / total:.1f}%'
            ax_sent.annotate(percentage, (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 5), textcoords='offset points')
    visuals['sentiment_chart'] = fig_sent
    
    # --- Word Cloud ---
    stopwords_es = ['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'm√°s', 'mas', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'ha', 'me', 'si', 'porque', 'esta', 'cuando', 'muy', 'sin', 'sobre', 'tambi√©n', 'fue', 'hasta', 'hay', 'mi', 'eso', 'todo', 'est√°', 'son', 'qu√©', 'pero', 'eso', 'te', 'estar', 'as√≠', 'hacer', 'tiene', 'tienes', 'ser', 'eres', 'soy', 'es']
    text_for_cloud = ' '.join(df['Original Comment'].dropna())
    text_no_emojis = ''.join(c for c in text_for_cloud if c not in emoji.EMOJI_DATA)
    if text_no_emojis.strip():
        wc = WordCloud(width=800, height=400, background_color='white',
                       stopwords=set(stopwords_es), collocations=False,
                       color_func=wordcloud_color_func # ¬°Aqu√≠ le decimos que use la funci√≥n de color que elegiste!
                      ).generate(text_for_cloud)
        fig_wc, ax_wc = plt.subplots(figsize=(10, 5)) # Un tama√±o mejor para la nube de palabras
        ax_wc.imshow(wc, interpolation='bilinear')
        ax_wc.axis('off')
        ax_wc.set_title('Word Cloud', fontsize=16) # Ponemos un t√≠tulo a la nube de palabras
        fig_wc, ax_wc = plt.subplots(); ax_wc.imshow(wc, interpolation='bilinear'); ax_wc.axis('off')
        visuals['word_cloud'] = fig_wc
        
    # --- Emoji Ranking ---
    all_emojis = [c for c in ''.join(df['Original Comment'].dropna()) if c in emoji.EMOJI_DATA]
    if all_emojis:
        visuals['emoji_ranking'] = Counter(all_emojis).most_common(5)
        
    return visuals


# ==========================================================================
# APP LAYOUT
# ==========================================================================
if "analysis_df" not in st.session_state: st.session_state.analysis_df = None
if "text_input_val" not in st.session_state: st.session_state.text_input_val = ""
if "chat_history" not in st.session_state: st.session_state.chat_history = []

# Inicializaci√≥n de las variables de color para que siempre existan
sentiment_colors_to_use = {
    'Positive': '#2ca02c',
    'Negative': '#d62728',
    'Neutral': '#ff7f0e'
}
wordcloud_color_func_to_use = None # Por defecto, la nube de palabras usa sus colores aleatorios
# Las variables 'image_for_colors' y 'extracted_colors' no necesitan inicializaci√≥n global aqu√≠
# porque solo se usan dentro del `if` de la barra lateral.

try:
    api_key = st.secrets["GOOGLE_API_KEY"]
except:
    st.error("FATAL ERROR: Your Google AI API Key is not configured in Streamlit Secrets."); st.stop()

# --- Sidebar ---
with st.sidebar:
    st.title("Controls")
    # --- Aqu√≠ empezamos con los controles para personalizar los colores ---
    st.markdown("---") # Pone una l√≠nea separadora bonita
    st.subheader("Personalizar Colores") # Un t√≠tulo para esta secci√≥n
    
    # --- Opciones para los colores del Gr√°fico de Sentimiento ---
    st.markdown("### Colores del Gr√°fico de Sentimiento")
    sentiment_palette_option = st.selectbox(
        "Elige c√≥mo quieres los colores del gr√°fico:",
        ["Por Defecto", "Colores Personalizados", "Colores de una Imagen"], # Opciones para el usuario
        key="sentiment_palette_option" # Un nombre √∫nico para este control
    )

    sentiment_colors_to_use = {} # Aqu√≠ guardaremos los colores que el usuario elija
    if sentiment_palette_option == "Por Defecto":
        sentiment_colors_to_use = {
            'Positive': '#2ca02c', # Verde por defecto
            'Negative': '#d62728', # Rojo por defecto
            'Neutral': '#ff7f0e'   # Naranja por defecto
        }
    elif sentiment_palette_option == "Colores Personalizados":
        st.write("O define tus propios colores:")
        sentiment_colors_to_use['Positive'] = st.color_picker('Color para POSITIVO', '#2ca02c', key="pos_color")
        sentiment_colors_to_use['Negative'] = st.color_picker('Color para NEGATIVO', '#d62728', key="neg_color")
        sentiment_colors_to_use['Neutral'] = st.color_picker('Color para NEUTRAL', '#ff7f0e', key="neu_color")
    
    # --- Opciones para los colores de la Nube de Palabras ---
    st.markdown("### Colores de la Nube de Palabras")
    wordcloud_color_option = st.selectbox(
        "Elige c√≥mo quieres los colores de la nube de palabras:",
        ["Por Defecto (Aleatorio)", "Azules", "Verdes", "Viridis", "Plasma", "Colores de una Imagen"],
        key="wordcloud_palette_option"
    )

    image_for_colors = None # Aqu√≠ guardaremos la imagen si el usuario sube una
    extracted_colors = [] # Aqu√≠ guardaremos los colores que saquemos de la imagen

    # Si el usuario elige sacar colores de una imagen para cualquier gr√°fico
    if sentiment_palette_option == "Colores de una Imagen" or wordcloud_color_option == "Colores de una Imagen":
        image_for_colors = st.file_uploader("Sube una imagen para sacar colores:", type=["png", "jpg", "jpeg"], key="color_image_uploader")
        if image_for_colors:
            try:
                extracted_colors = extract_colors_from_image(image_for_colors, num_colors=10) # Sacamos 10 colores
                st.info(f"Se sacaron {len(extracted_colors)} colores de la imagen.")
                
                # Si el gr√°fico de sentimiento debe usar colores de la imagen
                if sentiment_palette_option == "Colores de una Imagen":
                    if len(extracted_colors) >= 3: # Si hay suficientes colores
                        sentiment_colors_to_use['Positive'] = extracted_colors[0] # El primer color
                        sentiment_colors_to_use['Neutral'] = extracted_colors[1]  # El segundo
                        sentiment_colors_to_use['Negative'] = extracted_colors[2] # El tercero
                    else:
                        st.warning("No hay suficientes colores en la imagen para el gr√°fico de sentimiento. Usando colores por defecto.")
                        sentiment_colors_to_use = {
                            'Positive': '#2ca02c', 'Negative': '#d62728', 'Neutral': '#ff7f0e'
                        }
                
            except Exception as e:
                st.error(f"Error al procesar la imagen para sacar colores: {e}")
                extracted_colors = [] # Si hay un error, no hay colores extra√≠dos
        else:
            st.warning("Por favor, sube una imagen para usar la opci√≥n 'Colores de una Imagen'.")
            extracted_colors = []

    wordcloud_color_func_to_use = None # Esta ser√° la funci√≥n para la nube de palabras

    if wordcloud_color_option == "Azules":
        wordcloud_color_func_to_use = plt.cm.Blues # Una paleta de azules de Matplotlib
    elif wordcloud_color_option == "Verdes":
        wordcloud_color_func_to_use = plt.cm.Greens # Una paleta de verdes
    elif wordcloud_color_option == "Viridis":
        wordcloud_color_func_to_use = plt.cm.viridis
    elif wordcloud_color_option == "Plasma":
        wordcloud_color_func_to_use = plt.cm.plasma
    elif wordcloud_color_option == "Colores de una Imagen" and image_for_colors and extracted_colors:
        # Si elegimos colores de la imagen y hay colores
        from wordcloud import get_single_color_func
        if extracted_colors:
            # Creamos una funci√≥n que elija un color aleatorio de los que sacamos de la imagen
            wordcloud_color_func_to_use = lambda word, font_size, position, orientation, random_state, **kwargs: \
                                          extracted_colors[random_state.randint(0, len(extracted_colors) -1)]
        else:
             wordcloud_color_func_to_use = None # Si no hay colores, volvemos al por defecto
    else: # Si el usuario elige "Por Defecto (Aleatorio)" o si algo fall√≥
        wordcloud_color_func_to_use = None # La nube de palabras usar√° sus colores aleatorios por defecto

    # --- Fin de los controles de personalizaci√≥n de color ---
    st.markdown("---") # Otra l√≠nea separadora
    if st.session_state.analysis_df is not None:
        if st.button("Start New Analysis"):
            st.session_state.analysis_df = None; st.session_state.text_input_val = ""; st.session_state.chat_history = []; st.rerun()
    else:
        st.info("Analyze data to enable controls.")

# --- Main Content ---
if st.session_state.analysis_df is None:
    # --- Data Input View ---
    st.header("Comment Analysis Platform")
    st.markdown("Provide your data through one of the methods below to start the analysis.")
    input_container = st.container(border=True)
    with input_container:
        tab1, tab2, tab3 = st.tabs(["Paste Comments", "Upload Excel", "Google Sheets"])
        with tab1:
            st.session_state.text_input_val = st.text_area("Paste comments here:", height=250, value=st.session_state.text_input_val)
            if st.button("Clear"): st.session_state.text_input_val = ""; st.rerun()
        with tab2:
            uploaded_file = st.file_uploader("Upload Excel file", type=['xlsx'], label_visibility="collapsed")
        with tab3:
            gsheets_link = st.text_input("Paste Google Sheets link", label_visibility="collapsed")
    st.info("Note: For Excel and Google Sheets, the app will automatically analyze the first column.", icon="üí°")

    if st.button("‚ú® Analyze Now!"):
        comments = load_comments_from_source(uploaded_file, gsheets_link, st.session_state.text_input_val)
        if comments:
            st.session_state.analysis_df = run_batch_analysis(api_key, comments)
            st.rerun()
        else:
            st.warning("Please provide comments to analyze.")
else:
    # --- Results Dashboard View ---
    df = st.session_state.analysis_df
    st.header("Analysis Dashboard")
    
    with st.expander("üí¨ Open IA Chat to ask about these results"):
        # ... Chat logic remains the same
        # ...
        for message in st.session_state.chat_history:
            with st.chat_message(message["role"]): st.markdown(message["content"])
        if prompt := st.chat_input("Ask a question..."):
            st.session_state.chat_history.append({"role": "user", "content": prompt})
            with st.spinner("Thinking..."):
                model = genai.GenerativeModel('gemini-1.5-pro')
                context_for_ia = f"Dataframe:\n{st.session_state.analysis_df.to_string()}"
                full_prompt = f"You are an expert business analyst. Based on the following data analysis, answer the user's question concisely.\n--- DATA ---\n{context_for_ia}\n--- END DATA ---\nQUESTION: {prompt}"
                response = model.generate_content(full_prompt)
                st.session_state.chat_history.append({"role": "assistant", "content": response.text})
            st.rerun()
            
    visuals = generate_visuals(df, sentiment_colors_to_use, wordcloud_color_func_to_use)
    
    col1, col2 = st.columns([2, 1])
    with col1:
        if 'sentiment_chart' in visuals:
            with st.container(border=True): st.pyplot(visuals['sentiment_chart'])
    with col2:
        if 'emoji_ranking' in visuals:
            with st.container(border=True):
                st.subheader("Top Emojis")
                for emoji_char, count in visuals['emoji_ranking']:
                    st.markdown(f"### {emoji_char} &nbsp;&nbsp;`x{count}`")

    if 'word_cloud' in visuals:
        with st.container(border=True):
            st.subheader("Word Cloud")
            st.pyplot(visuals['word_cloud'])

    with st.container(border=True):
        st.subheader("Detailed Data")
        cols = df.columns.tolist()
        if 'Original Comment' in cols:
            cols.insert(0, cols.pop(cols.index('Original Comment')))
            st.dataframe(df[cols])
        else:
            st.dataframe(df)
